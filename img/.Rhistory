# Separando variáveis ​​numéricas e variáveis ​​de fator em dois novos dataframe
df_data_fact <- sapply(dados, is.factor)
data_fact <- dados[, df_data_fact]
head(data_fact)
head(data_fact)
rm(df_data_fact)
df_data_nub <- sapply(dados, is.factor)
df_data_nub <- sapply(dados, is.factor)
data_nub <- dados[, df_data_nub]
head(data_nub)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
title('Correlação de Pearson')
df_data_nub <- sapply(dados, is.factor)
data_nub <- dados[, df_data_nub]
df_data_nub <- sapply(dados, is.factor)
data_nub <- dados[, df_data_nub]
head(data_nub)
rm(data_nub)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
## Importando bibliotecas
library("readxl")
library("naniar")
library("corrplot")
library("dplyr")
library("sqldf")
library("ggplot2")
library("caret")
library("repr")
## Carregando base dados
dados <- read_excel("1.Machine Learning - Logística prevendo o consumo de energia de carros elétricos/FEV-data-Excel.xlsx")
dados
# Verficando número de linhas
nrow(dados)
# Linhas e colunas
dim(dados)
# Verificando os cienco primeiros dados
head(dados)
# Verificando os últimos dados
tail(dados)
str(dados)
# Resumo estatístico das variáveis numéricas
summary(dados)
## Limpeza de dados - NA
sum(is.na(dados))
sum(!complete.cases(dados))
# Visualizando os valores de missing
options(repr.plot.width=15, repr.plot.height = 9)
vis_miss(dados)
data_perc <- round(sum(! complete.cases(dados)) / (dim(dados)[1]) * 100, 2)
cat(data_perc, "%")
dados <- na.omit(dados)
sum(is.na(dados))
dados <- dados[,-c(1,2,3)]
head(dados)
# Renomerando as colunas
data_col <- c("price", "power", "torque",
"brakes", "drive_type","battery_cap",
"range", "wheelbase", "length",
"width", "heigth","min_emp_weight",
"perm_gross_weigth", "max_load_cap",
"n_seats","n_doors", "tire_size",
"max_speed", "boot_cap", "acceleration",
"max_dc", "energy_consumption")
colnames(dados) <- data_col
# Visualizando dataset
dados
# Verificando as colunas com menos de 5 valores exclusivos e convertendo essas variáveis ​​em fatores
data_unique <- sapply(dados, function(col) length(unique(col))<=5)
dados[, data_unique] <- lapply(dados[ , data_unique], factor)
str(dados)
rm(data_unique)
# Separando variáveis ​​numéricas e variáveis ​​de fator em dois novos dataframe
df_data_fact <- sapply(dados, is.factor)
data_fact <- dados[, df_data_fact]
head(data_fact)
rm(df_data_fact)
df_data_nub <- sapply(dados, is.factor)
data_nub <- dados[, df_data_nub]
head(data_nub)
rm(data_nub)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
df_data_nub <- sapply(dados, is.numeric)
data_nub <- dados[, df_data_nub]
head(data_nub)
rm(data_nub)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
gc()
## Importando bibliotecas
library("readxl")
library("naniar")
library("corrplot")
library("dplyr")
library("sqldf")
library("ggplot2")
library("caret")
library("repr")
## Carregando base dados
dados <- read_excel("1.Machine Learning - Logística prevendo o consumo de energia de carros elétricos/FEV-data-Excel.xlsx")
dados
# Verficando número de linhas
nrow(dados)
# Linhas e colunas
dim(dados)
# Verificando os cienco primeiros dados
head(dados)
# Verificando os últimos dados
tail(dados)
str(dados)
# Resumo estatístico das variáveis numéricas
summary(dados)
## Limpeza de dados - NA
sum(is.na(dados))
sum(!complete.cases(dados))
# Visualizando os valores de missing
options(repr.plot.width=15, repr.plot.height = 9)
vis_miss(dados)
data_perc <- round(sum(! complete.cases(dados)) / (dim(dados)[1]) * 100, 2)
cat(data_perc, "%")
dados <- na.omit(dados)
sum(is.na(dados))
dados <- dados[,-c(1,2,3)]
head(dados)
# Renomerando as colunas
data_col <- c("price", "power", "torque",
"brakes", "drive_type","battery_cap",
"range", "wheelbase", "length",
"width", "heigth","min_emp_weight",
"perm_gross_weigth", "max_load_cap",
"n_seats","n_doors", "tire_size",
"max_speed", "boot_cap", "acceleration",
"max_dc", "energy_consumption")
colnames(dados) <- data_col
# Visualizando dataset
dados
# Verificando as colunas com menos de 5 valores exclusivos e convertendo essas variáveis ​​em fatores
data_unique <- sapply(dados, function(col) length(unique(col))<=5)
dados[, data_unique] <- lapply(dados[ , data_unique], factor)
str(dados)
rm(data_unique)
# Separando variáveis ​​numéricas e variáveis ​​de fator em dois novos dataframe
df_data_fact <- sapply(dados, is.factor)
data_fact <- dados[, df_data_fact]
head(data_fact)
rm(df_data_fact)
df_data_nub <- sapply(dados, is.numeric)
data_nub <- dados[, df_data_nub]
head(data_nub)
rm(data_nub)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_nub), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
title('Correlação de Pearson')
corr_eng <- cor(data_num[,colnames(data_num) != "energy_consumption"],
dados$energy_consumption)
## Feature Selection
data <- row.names(which(abs(energy_cor)>0.5, arr.ind = T))
# Separando variáveis ​​numéricas e variáveis ​​de fator em dois novos dataframe
is_factors1 <- sapply(dados, is.factor)
data_factors1 <- dados[, is_factors1]
head(data_factors1)
rm(is_factors1)
is_numeric1 <- sapply(data, is.numeric)
data_numeric1 <- dados[, is_numeric1]
is_numeric1 <- sapply(dados, is.numeric)
data_numeric1 <- dados[, is_numeric1]
head(data_numeric1)
rm(is_numeric1)
## Correlação
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_numeric1), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
title('Correlação de Pearson')
corr_eng <- cor(data_numeric1[,colnames(data_numeric1) != "energy_consumption"],
dados$energy_consumption)
corr_eng <- cor(data_numeric1[,colnames(data_numeric1) != "energy_consumption"],
dados$energy_consumption)
corr_eng
## Feature Selection
data <- row.names(which(abs(corr_eng)>0.5, arr.ind = T))
data
## Feature Selection
data_train <- row.names(which(abs(corr_eng)>0.5, arr.ind = T))
data_train
data_train <- data_train[! data_train %in% c('length', 'wheelbase', 'min_emp_weight',
'max_load_cap', 'tire_size', 'boot_cap',
'torque', 'max_speed', 'acceleration',
'max_dc')]
data_train
data_df <- append(data_train, c('drive_type', 'energy_consumption'))
data_df
base <- dados[, data_df]
head(base)
str(df)
str(base)
base$drive_type <- as.factor(base$drive_type)
base
base$drive_type <- as.factor(base$drive_type)
str(base)
# Pré-processamento dos dados
dados
# Pré-processamento dos dados
base
train <- createDataPartition(base$power, p = 0.8, list = FALSE)
x_train <- base[train, ]
y_test <- base[-train, ]
# Treinar o modelo de regressão linear
modelo <- lm(energy_consumption ~., data = base)
modelo
# Treinar o modelo de regressão linear
model_reg_lin <- lm(energy_consumption ~.,
data = x_train)
model_reg_lin
summary(model_reg_lin)
# Previsãoes modelo 1
pred_reg <- predict(model_reg_lin, newdata = y_test)
# Previsãoes modelo 1
pred_reg <- predict(model_reg_lin, newdata = y_test)
pred_reg
# Calcular o erro médio absoluto (MAE)
mae <- mean(abs(y_test$energy_consumption - pred_reg))
cat("Erro Médio Absoluto (MAE):", mae, "\n")
# Calcular o coeficiente de determinação (R²)
r_squared <- cor(y_test$energy_consumption, pred_reg)^2
cat("Coeficiente de Determinação (R²):", r_squared, "\n")
# Exemplo de novos dados para previsão
novos_dados <- data.frame(tipo_motor = "motor_tipo_1",
num_motores = 2,
peso_veiculo = 1500,
capacidade_carga = 500)
# Fazer previsões com o modelo treinado
previsao_novos_dados <- predict(model_reg_lin, newdata = novos_dados)
# Exemplo de novos dados para previsão
novos_dados <- data.frame(tipo_motor = "motor_tipo_1",
num_motores = 2,
peso_veiculo = 1500,
capacidade_carga = 500,
price = 50000)
# Fazer previsões com o modelo treinado
previsao_novos_dados <- predict(model_reg_lin, newdata = novos_dados)
cat("Previsão de consumo de energia:", previsao_novos_dados, "\n")
# Pré-processamento dos dados
base
# Modelo machine learning 2 - Regressão linear múltipla
# Treinar o modelo de regressão linear múltipla
modelo <- lm(energy_consumption ~ price +
power + battery_cap +
energy_consumption,
data = base)
# Sumário do modelo
summary(modelo)
# Modelo machine learning 2 - Regressão linear múltipla
# Treinar o modelo de regressão linear múltipla
model_reg_lin_2 <- lm(energy_consumption ~ price +
power + battery_cap +
energy_consumption,
data = base)
# Sumário do modelo
summary(model_reg_lin_2)
# Modelo machine learning 2 - Regressão linear múltipla
# Treinar o modelo de regressão linear múltipla
model_reg_lin_2 <- lm(energy_consumption ~ price +
power + battery_cap +
energy_consumption,
data = x_train)
# Sumário do modelo
summary(model_reg_lin_2)
# Previsãoes modelo 2
pred_reg2 <- predict(model_reg_lin_2, newdata = y_test)
pred_reg2
# Previsãoes modelo 2
pred_reg2 <- predict(model_reg_lin_2, newdata = y_test)
# Modelo machine learning 2 - Regressão linear múltipla
# Treinar o modelo de regressão linear múltipla
model_reg_lin_2 <- lm(energy_consumption ~ drive_type, data = base)
# Sumário do modelo
summary(model_reg_lin_2)
# Previsãoes modelo 2
pred_reg2 <- predict(model_reg_lin_2, newdata = y_test)
pred_reg2
# Validação Cruzada com K-fold
model_k <- trainControl(method = "cv", number = 5)
model_k_val <- train(energy_consumption ~ drive_type, data = base, method = "lm", trControl = model_k)
model_k_val <- train(energy_consumption ~ drive_type,
data = base,
method = "lm",
trControl = model_k)
model_k_val
model_k_val$resample
# Previsãoes modelo 2
pred_reg2 <- predict(model_reg_lin_2, newdata = y_test)
pred_reg2
# Calcular o erro médio absoluto (MAE)
mae <- mean(abs(y_test$energy_consumption - pred_reg2))
cat("Erro Médio Absoluto (MAE):", mae, "\n")
# Calcular o coeficiente de determinação (R²)
r_squared <- cor(y_test$energy_consumption, pred_reg2)^2
cat("Coeficiente de Determinação (R²):", r_squared, "\n")
# Exemplo de novos dados para previsão
novos_dados <- data.frame(tipo_motor = "motor_tipo_1",
num_motores = 2,
peso_veiculo = 1500,
capacidade_carga = 500)
# Fazer previsões com o modelo treinado
previsao_novos_dados <- predict(model_reg_lin_2,
newdata = novos_dados)
# Exemplo de novos dados para previsão
novos_dados <- data.frame(tipo_motor = "motor_tipo_1",
num_motores = 2,
peso_veiculo = 1500,
capacidade_carga = 500)
# Fazer previsões com o modelo treinado
previsao_novos_dados <- predict(model_reg_lin_2,
newdata = novos_dados)
base
# Novos dados para previsão
novos_dados <- data.frame(
power = c(170, 190, 200),
battery_cap = c(75, 80, 90),
perm_gross_weigth = c(1300, 1350, 1400),
drive_type = c("FWD", "RWD", "AWD"),
energy_consumption = c(21, 23, 25)
)
# Fazer previsões com base nos novos dados
previsoes_novos_dados <- predict(model_reg_lin_2, newdata = novos_dados)
# Verificar os níveis da variável drive_type no conjunto de treinamento
niveis_drive_type <- levels(dados$drive_type)
# Ajustar os níveis da variável drive_type nos novos dados
novos_dados$drive_type <- factor(novos_dados$drive_type,
levels = niveis_drive_type)
# Fazer previsões com base nos novos dados ajustados
previsoes_novos_dados <- predict(model_reg_lin_2, newdata = novos_dados)
# Mostrar as previsões
print(previsoes_novos_dados)
# Obter os resíduos do modelo
residuos <- residuals(model_reg_lin_2)
# Mostrar os resíduos
print(residuos)
# Calcular o RMSE
rmse <- sqrt(mean((y_test$energy_consumption - predict(model_reg_lin_2))^2))
cat("Coeficiente de Determinação (R²):", rmse, "\n")
# Calcular o RMSE
rmse <- sqrt(mean((y_test$energy_consumption - predict(model_reg_lin_2))^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Criar um dataframe com os valores observados e as previsões
dados_previsoes <- data.frame(
price_observed = dados$price,
price_predicted = predict(modelo)
)
# Gráfico previsão modelo regressão
# Fazer previsões usando o modelo
base$pred_reg2 <- predict(model_reg_lin_2)
# Gráfico de dispersão com linha de previsão
plot(base$energy_consumption, base$pred_reg2, main = "Gráfico de Previsão",
xlab = "Valores Reais", ylab = "Previsões", col = "blue", pch = 16)
abline(0, 1, col = "red", lwd = 2)  # Adiciona a linha de referência y = x
install.packages("naniar")
install.packages("sqldf")
install.packages("sqldf")
install.packages("naniar")
library("readxl")
library("naniar")
library("corrplot")
library("dplyr")
library("sqldf")
library("ggplot2")
library("caret")
library("repr")
dados <- read_excel("1.Machine Learning - Logística prevendo o consumo de energia de carros elétricos/FEV-data-Excel.xlsx")
dados
# Visualizando os dados em formato
View(dados)
# Verficando número de linhas
nrow(dados)
# Linhas e colunas
dim(dados)
# Verificando os cienco primeiros dados
head(dados)
# Verificando os últimos dados
tail(dados)
# Resumo estatístico das variáveis numéricas
summary(dados)
## Limpeza de dados - NA
sum(is.na(dados))
sum(!complete.cases(dados))
# Visualizando os valores de missing
options(repr.plot.width=15, repr.plot.height = 9)
vis_miss(dados)
data_perc <- round(sum(! complete.cases(dados)) / (dim(dados)[1]) * 100, 2)
cat(data_perc, "%")
dados <- na.omit(dados)
sum(is.na(dados))
dados <- dados[,-c(1,2,3)]
head(dados)
# Renomerando as colunas
data_col <- c("price", "power", "torque",
"brakes", "drive_type","battery_cap",
"range", "wheelbase", "length",
"width", "heigth","min_emp_weight",
"perm_gross_weigth", "max_load_cap",
"n_seats","n_doors", "tire_size",
"max_speed", "boot_cap", "acceleration",
"max_dc", "energy_consumption")
colnames(dados) <- data_col
# Visualizando dataset
dados
# Verificando as colunas com menos de 5 valores exclusivos e convertendo essas variáveis em fatores
data_unique <- sapply(dados, function(col) length(unique(col))<=5)
dados[, data_unique] <- lapply(dados[ , data_unique], factor)
str(dados)
rm(data_unique)
# Separando variáveis numéricas e variáveis de fator em dois novos dataframe
is_factors1 <- sapply(dados, is.factor)
data_factors1 <- dados[, is_factors1]
head(data_factors1)
rm(is_factors1)
is_numeric1 <- sapply(dados, is.numeric)
data_numeric1 <- dados[, is_numeric1]
head(data_numeric1)
rm(is_numeric1)
options(repr.plot.width=8, repr.plot.height = 8)
corrplot(cor(data_numeric1), method="color",tl.col= "black",tl.srt=60
, type = "upper", diag= FALSE)
title('Correlação de Pearson')
corr_eng <- cor(data_numeric1[,colnames(data_numeric1) != "energy_consumption"],
dados$energy_consumption)
corr_eng
data_train <- row.names(which(abs(corr_eng)>0.5, arr.ind = T))
data_train
data_train <- data_train[! data_train %in% c('length', 'wheelbase', 'min_emp_weight',
'max_load_cap', 'tire_size', 'boot_cap',
'torque', 'max_speed', 'acceleration',
'max_dc')]
data_train
data_df <- append(data_train, c('drive_type', 'energy_consumption'))
data_df
base <- dados[, data_df]
head(base)
str(base)
base$drive_type <- as.factor(base$drive_type)
str(base)
# Dividir os dados em conjunto de treinamento (80%) e conjunto de teste (20%)
set.seed(123) # Define uma semente para a reproducibilidade dos resultados
train <- createDataPartition(base$power, p = 0.8, list = FALSE)
x_train <- base[train, ]
y_test <- base[-train, ]
# Treinar o modelo de regressão linear
model_reg_lin <- lm(energy_consumption ~.,
data = x_train)
model_reg_lin
# Summary modelo
summary(model_reg_lin)
# Previsãoes modelo 1
pred_reg <- predict(model_reg_lin, newdata = y_test)
pred_reg
# Calcular o erro médio absoluto (MAE)
mae <- mean(abs(y_test$energy_consumption - pred_reg))
cat("Erro Médio Absoluto (MAE):", mae, "\n")
# Calcular o coeficiente de determinação (R²)
r_squared <- cor(y_test$energy_consumption, pred_reg)^2
cat("Coeficiente de Determinação (R²):", r_squared, "\n")
# Modelo machine learning 2 - Regressão linear múltipla
# Treinar o modelo de regressão linear múltipla
model_reg_lin_2 <- lm(energy_consumption ~ drive_type, data = base)
model_reg_lin_2
# Sumário do modelo
summary(model_reg_lin_2)
# Previsãoes modelo 2
pred_reg2 <- predict(model_reg_lin_2, newdata = y_test)
pred_reg2
# Obter os resíduos do modelo
residuos <- residuals(model_reg_lin_2)
# Mostrar os resíduos
print(residuos)
# Calcular o erro médio absoluto (MAE)
mae <- mean(abs(y_test$energy_consumption - pred_reg2))
cat("Erro Médio Absoluto (MAE):", mae, "\n")
# Calcular o coeficiente de determinação (R²)
r_squared <- cor(y_test$energy_consumption, pred_reg2)^2
cat("Coeficiente de Determinação (R²):", r_squared, "\n")
# Calcular o RMSE
rmse <- sqrt(mean((y_test$energy_consumption - predict(model_reg_lin_2))^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Validação Cruzada com K-fold
model_k <- trainControl(method = "cv", number = 5)
model_k_val <- train(energy_consumption ~ drive_type,
data = base,
method = "lm",
trControl = model_k)
# Visualizando modelo k-fold
model_k_val
model_k_val$resample
