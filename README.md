# Projetos_dsa

[![MIT License](https://img.shields.io/apm/l/atomic-design-ui.svg?)](https://github.com/tterb/atomic-design-ui/blob/master/LICENSEs)
[![GPLv3 License](https://img.shields.io/badge/License-GPL%20v3-yellow.svg)](https://opensource.org/licenses/)
[![AGPL License](https://img.shields.io/badge/license-AGPL-blue.svg)](http://www.gnu.org/licenses/agpl-3.0)
[![author](https://img.shields.io/badge/author-RafaelGallo-red.svg)](https://github.com/RafaelGallo?tab=repositories) 
[![](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/release/python-374/) 
[![](https://img.shields.io/badge/R-3.6.0-red.svg)](https://www.r-project.org/)
[![](https://img.shields.io/badge/ggplot2-white.svg)](https://ggplot2.tidyverse.org/)
[![](https://img.shields.io/badge/dplyr-blue.svg)](https://dplyr.tidyverse.org/)
[![](https://img.shields.io/badge/readr-green.svg)](https://readr.tidyverse.org/)
[![](https://img.shields.io/badge/ggvis-black.svg)](https://ggvis.tidyverse.org/)
[![](https://img.shields.io/badge/Shiny-red.svg)](https://shiny.tidyverse.org/)
[![](https://img.shields.io/badge/plotly-green.svg)](https://plotly.com/)
[![](https://img.shields.io/badge/XGBoost-red.svg)](https://xgboost.readthedocs.io/en/stable/#)
[![](https://img.shields.io/badge/Tensorflow-orange.svg)](https://powerbi.microsoft.com/pt-br/)
[![](https://img.shields.io/badge/Keras-red.svg)](https://powerbi.microsoft.com/pt-br/)
[![](https://img.shields.io/badge/CUDA-gree.svg)](https://powerbi.microsoft.com/pt-br/)
[![](https://img.shields.io/badge/Caret-orange.svg)](https://caret.tidyverse.org/)
[![](https://img.shields.io/badge/Pandas-blue.svg)](https://pandas.pydata.org/) 
[![](https://img.shields.io/badge/Matplotlib-blue.svg)](https://matplotlib.org/)
[![](https://img.shields.io/badge/Seaborn-green.svg)](https://seaborn.pydata.org/)
[![](https://img.shields.io/badge/Matplotlib-orange.svg)](https://scikit-learn.org/stable/) 
[![](https://img.shields.io/badge/Scikit_Learn-green.svg)](https://scikit-learn.org/stable/)
[![](https://img.shields.io/badge/Numpy-white.svg)](https://numpy.org/)
[![](https://img.shields.io/badge/PowerBI-red.svg)](https://powerbi.microsoft.com/pt-br/)

![Logo](https://img.freepik.com/vetores-gratis/conceito-de-transformacao-digital-de-vetor-de-fundo-de-cerebro-de-tecnologia-de-ia_53876-117820.jpg?w=740&t=st=1689030857~exp=1689031457~hmac=aa37a3a3621763858ce92de1446f37fa4913d5ff5fe9a81569850c90d751a485)

Neste repositório, você encontrará os projetos práticos que realizei ao longo do meu caminho para me tornar um cientista de dados. Esses projetos foram desenvolvidos como parte dos cursos que fiz, incluindo "Big Data Analytics com R e Azure Machine Learning", "Big Data Real-time Analytics com Python e Spark", "Machine Learning", "Business Analytics", "Visualização de Dados e Design de Dashboards" e "Engenharia de Dados com Hadoop e Spark".

Durante minha formação como cientista de dados, tive a oportunidade de trabalhar em diversos projetos interessantes. Alguns desses projetos resultaram em ótimos resultados e forneceram valiosas experiências. Ao aplicar os conhecimentos adquiridos nos cursos, pude enfrentar desafios reais e desenvolver soluções inovadoras.
Ao explorar este repositório, você encontrará uma variedade de projetos que abrangem diferentes áreas da ciência de dados. Esses projetos refletem a minha habilidade em lidar com análise de big data, uso de técnicas de machine learning, análise de negócios, visualização de dados e criação de dashboards, além de engenharia de dados com o uso de tecnologias como Hadoop e Spark. Cada projeto representa um marco em minha jornada como cientista de dados e destaca minha capacidade de aplicar conceitos teóricos em cenários práticos. Estou entusiasmado em compartilhar esses projetos com você e espero que eles demonstrem meu conhecimento e habilidades como cientista de dados. 

Em conclusão, este repositório apresenta os projetos que desenvolvi durante minha formação como cientista de dados, utilizando habilidades e conhecimentos adquiridos em cursos como "Big Data Analytics com R e Azure Machine Learning", "Big Data Real-time Analytics com Python e Spark", "Machine Learning", "Business Analytics", "Visualização de Dados e Design de Dashboards" e "Engenharia de Dados com Hadoop e Spark". Esses projetos representam minha capacidade de enfrentar desafios reais, aplicar técnicas avançadas de análise de dados e criar soluções inovadoras. Espero que você encontre inspiração e insights valiosos ao explorar esses projetos.

# Descrição projetos na prática 

Projeto 01 - Logística prevendo o consumo de energia de carros elétricos - (Big Data Analytics com R e Microsoft Azure Machine Learning)
[R](https://github.com/Delta357/Projetos_dsa/blob/main/notebook/Projeto_1/R/model_ml_predict.r)

Projeto 02 - Segurança do trabalho prevendo a eficiência  de extintores de incendio - (Big Data Analytics com R e Microsoft Azure Machine Learning)
[R](https://github.com/Delta357/Projetos_dsa/blob/main/notebook/Projeto_2/R/src/model_ml.r)

Projeto 03 - Análise de risco no transporte público - (Big Data Real-Time Analytics com Python e Spark)
[notebook]()

Projeto 04 - Análise de sentimento em tweets ChatGPT com pyspark (Big Data Real-Time Analytics com Python e Spark)
[notebook_python](https://github.com/Delta357/Projetos_dsa/blob/main/notebook/Projeto_4/notebook/nlp_pyspark%20(2).ipynb)

Projeto 05 - Implementando Slow Changing - (Engenharia de Dados com Hadoop e Spark)
[notebook]()

Projeto 06 - Processamento de Logs em Tempo Real - (Engenharia de Dados com Hadoop e Spark)
[notebook]()

Projeto 07 - Medicina personalizada redefinindo o tratamento de câncer - (Machine learning)
[notebook_python](https://github.com/Delta357/Projetos_dsa/blob/main/notebook/Projeto_7/notebook/Projeto_DSA_ANN.ipynb)

Projeto 08 - Modelagem preditiva em iot - (Machine learning)
[R](https://github.com/Delta357/Projetos_dsa/blob/main/notebook/Projeto%208/notebook/model_iot_pred2.r)

Projeto 09 - Prevendo tendências macroeconômicas - (Business analytics)
[notebook]()

Projeto 10 - Sistema de Recomendação rede varejo - (Business analytics)
[notebook]()

Projeto 11 - Modelos Preditivos - (Visualização de Dados e Design de Dashboards)
[notebook]()

Projeto 12 - Design de Arquitetura Para Projetos IoT analytics - (Visualização de Dados e Design de Dashboards)
[notebook]()

## Stack utilizada

**Programação** Python, R.

**Machine learning**: Scikit-learn.

**Deep learning**: Keras, Tensorflow.

**Leitura CSV**: Pandas.

**Análise de dados**: Seaborn, Matplotlib.

**Modelo machine learning - Processo de linguagem natural**: NLTK, TextBlob, Vander.

## Variáveis de Ambiente

Para rodar esse projeto, você vai precisar adicionar as seguintes variáveis de ambiente no seu .env

`API_KEY`

`ANOTHER_API_KEY`


## Instalação

Instalação das bibliotecas para esse projeto no python.

```bash
  conda install pandas 
  conda install scikitlearn
  conda install numpy
  conda install scipy
  conda install matplotlib

  python==3.6.4
  numpy==1.13.3
  scipy==1.0.0
  matplotlib==2.1.2
```
Instalação do Python É altamente recomendável usar o anaconda para instalar o python. Clique aqui para ir para a página de download do Anaconda https://www.anaconda.com/download. Certifique-se de baixar a versão Python 3.6. Se você estiver em uma máquina Windows: Abra o executável após a conclusão do download e siga as instruções. 

Assim que a instalação for concluída, abra o prompt do Anaconda no menu iniciar. Isso abrirá um terminal com o python ativado. Se você estiver em uma máquina Linux: Abra um terminal e navegue até o diretório onde o Anaconda foi baixado. 
Altere a permissão para o arquivo baixado para que ele possa ser executado. Portanto, se o nome do arquivo baixado for Anaconda3-5.1.0-Linux-x86_64.sh, use o seguinte comando: chmod a x Anaconda3-5.1.0-Linux-x86_64.sh.

Agora execute o script de instalação usando.


Depois de instalar o python, crie um novo ambiente python com todos os requisitos usando o seguinte comando

```bash
conda env create -f environment.yml
```
Após a configuração do novo ambiente, ative-o usando (windows)
```bash
activate "Nome do projeto"
```
ou se você estiver em uma máquina Linux
```bash
source "Nome do projeto" 
```
Agora que temos nosso ambiente Python todo configurado, podemos começar a trabalhar nas atribuições. Para fazer isso, navegue até o diretório onde as atribuições foram instaladas e inicie o notebook jupyter a partir do terminal usando o comando
```bash
jupyter notebook
```

## Demo modelo machine learning

```
# Importação das bibliotecas de nlp
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Gerar dados de exemplo
X, y = make_classification(n_samples=1000, n_features=10, random_state=42)

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Criar o classificador Gradient Boosting
gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)

# Treinar o classificador
gb_classifier.fit(X_train, y_train)

# Fazer previsões no conjunto de teste
y_pred = gb_classifier.predict(X_test)

# Calcular a precisão do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Precisão do modelo:", accuracy)

## Aplicação em R
library(xgboost)

# Gerar dados de exemplo
data <- matrix(rnorm(1000), ncol = 10)
labels <- sample(c(0, 1), 100, replace = TRUE)

# Dividir os dados em conjunto de treinamento e teste
train_indices <- sample(1:100, 80)
train_data <- data[train_indices, ]
train_labels <- labels[train_indices]
test_data <- data[-train_indices, ]
test_labels <- labels[-train_indices]

# Criar a matriz de dados específica do xgboost
dtrain <- xgb.DMatrix(data = as.matrix(train_data), label = train_labels)
dtest <- xgb.DMatrix(data = as.matrix(test_data), label = test_labels)

# Definir os parâmetros do modelo
params <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eta = 0.1,
  max_depth = 3,
  nthread = 2,
  eval_metric = "error"
)

# Treinar o modelo
model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100
)

# Fazer previsões no conjunto de teste
pred <- predict(model, dtest)

# Calcular a precisão do modelo
accuracy <- sum(pred > 0.5 == test_labels) / length(test_labels)
print(paste("Precisão do modelo:", accuracy))
```

## Melhorias
Que melhorias você fez no seu código? 
- Ex: refatorações, melhorias de performance, acessibilidade, etc

## Suporte
Para suporte, mande um email para rafaelhenriquegallo@gmail.com

# Citação
@Data Science Academy
https://www.datascienceacademy.com.br
