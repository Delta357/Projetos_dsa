ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valor ideal de k (onde a precisão é máxima)
best_k <- k_values[which.max(precision_values)]
# Valor ideal de k (onde a precisão é máxima)
best_k <- k_values[which.max(precision_values)]
best_k
# Recomendação final para o filme de índice 1 usando o valor ideal de k
recommended_movies <- recommend_movies(1, movies, best_k)
# Exibindo os filmes recomendados
print(recommended_movies)
# Valores de k para o KNN
k_values <- seq(1, 5, 10)
precision_values <- c()
# Loop para avaliar o desempenho do modelo KNN para diferentes valores de k
for (k in k_values) {
# Exemplo de recomendação para o filme de índice 1
movie_index <- 1
recommended_movies <- recommend_movies(movie_index, movies, k)
# Avaliar a precisão das recomendações (exemplo: supondo que o filme correto seja o índice 2)
precision <- sum(recommended_movies == 2) / k
precision_values <- c(precision_values, precision)
}
# Plot dos melhores valores de k
plot_data <- data.frame(k = k_values, precision = precision_values)
ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valor ideal de k (onde a precisão é máxima)
best_k <- k_values[which.max(precision_values)]
best_k
# Carregue as bibliotecas
library(proxy)
library(class)
library(ggplot2)
# Dados de exemplo (matriz de similaridade)
movies <- matrix(c(1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1), nrow = 5, ncol = 5, byrow = TRUE)
# Função para calcular a similaridade do cosseno
cosine_similarity <- function(a, b) {
return(1 - proxy::simil(a, b, method = "cosine"))
}
# Função para recomendar filmes usando KNN
recommend_movies <- function(movie_index, movies, k) {
similarities <- apply(movies, 1, cosine_similarity, b = movies[movie_index, ])
sorted_indices <- order(similarities, decreasing = TRUE)
return(sorted_indices[1:k])
}
# Valores de k para o KNN
k_values <- seq(1, 5, 1)
precision_values <- c()
# Loop para avaliar o desempenho do modelo KNN para diferentes valores de k
for (k in k_values) {
# Exemplo de recomendação para o filme de índice 1
movie_index <- 1
recommended_movies <- recommend_movies(movie_index, movies, k)
# Avaliar a precisão das recomendações (exemplo: supondo que o filme correto seja o índice 2)
precision <- sum(recommended_movies == 2) / k
precision_values <- c(precision_values, precision)
}
# Plot dos melhores valores de k
plot_data <- data.frame(k = k_values, precision = precision_values)
ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valores de k para o KNN
k_values <- seq(1, 10)
precision_values <- c()
# Loop para avaliar o desempenho do modelo KNN para diferentes valores de k
for (k in k_values) {
# Exemplo de recomendação para o filme de índice 1
movie_index <- 1
recommended_movies <- recommend_movies(movie_index, movies, k)
# Avaliar a precisão das recomendações (exemplo: supondo que o filme correto seja o índice 2)
precision <- sum(recommended_movies == 2) / k
precision_values <- c(precision_values, precision)
}
# Plot dos melhores valores de k
plot_data <- data.frame(k = k_values, precision = precision_values)
ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valor ideal de k (onde a precisão é máxima)
best_k <- k_values[which.max(precision_values)]
# Valores de k para o KNN
k_values <- seq(1, 10, 15)
precision_values <- c()
# Loop para avaliar o desempenho do modelo KNN para diferentes valores de k
for (k in k_values) {
# Exemplo de recomendação para o filme de índice 1
movie_index <- 1
recommended_movies <- recommend_movies(movie_index, movies, k)
# Avaliar a precisão das recomendações (exemplo: supondo que o filme correto seja o índice 2)
precision <- sum(recommended_movies == 2) / k
precision_values <- c(precision_values, precision)
}
# Plot dos melhores valores de k
plot_data <- data.frame(k = k_values, precision = precision_values)
ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valor ideal de k (onde a precisão é máxima)
best_k <- k_values[which.max(precision_values)]
# Valores de k para o KNN
k_values <- seq(1, 5, 15)
precision_values <- c()
# Loop para avaliar o desempenho do modelo KNN para diferentes valores de k
for (k in k_values) {
# Exemplo de recomendação para o filme de índice 1
movie_index <- 1
recommended_movies <- recommend_movies(movie_index, movies, k)
# Avaliar a precisão das recomendações (exemplo: supondo que o filme correto seja o índice 2)
precision <- sum(recommended_movies == 2) / k
precision_values <- c(precision_values, precision)
}
# Plot dos melhores valores de k
plot_data <- data.frame(k = k_values, precision = precision_values)
ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valores de k para o KNN
k_values <- seq(1, 5, 10)
precision_values <- c()
# Loop para avaliar o desempenho do modelo KNN para diferentes valores de k
for (k in k_values) {
# Exemplo de recomendação para o filme de índice 1
movie_index <- 1
recommended_movies <- recommend_movies(movie_index, movies, k)
# Avaliar a precisão das recomendações (exemplo: supondo que o filme correto seja o índice 2)
precision <- sum(recommended_movies == 2) / k
precision_values <- c(precision_values, precision)
}
# Plot dos melhores valores de k
plot_data <- data.frame(k = k_values, precision = precision_values)
ggplot(data = plot_data, aes(x = k, y = precision)) +
geom_line() +
geom_point() +
labs(x = "Valor de k", y = "Precisão") +
ggtitle("Desempenho do modelo KNN para diferentes valores de k")
# Valor ideal de k (onde a precisão é máxima)
best_k <- k_values[which.max(precision_values)]
# Recomendação final para o filme de índice 1 usando o valor ideal de k
recommended_movies <- recommend_movies(1, movies, best_k)
# Exibindo os filmes recomendados
print(recommended_movies)
install.packages("shiny")
library(shiny)
library(ggplot2)
# Definindo a UI (interface do usuário)
ui <- fluidPage(
titlePanel("Exemplo de Aplicação Shiny"),
sidebarLayout(
sidebarPanel(
sliderInput("num_points", "Número de pontos:",
min = 10, max = 1000, value = 100)
),
mainPanel(
plotOutput("scatter_plot")
)
)
)
# Definindo o server (servidor)
server <- function(input, output) {
# Gerando os dados aleatórios com base no número de pontos escolhido pelo usuário
data <- reactive({
num_points <- input$num_points
data <- data.frame(
x = rnorm(num_points),
y = rnorm(num_points)
)
data
})
# Gerando o gráfico de dispersão
output$scatter_plot <- renderPlot({
data <- data()
ggplot(data, aes(x = x, y = y)) +
geom_point()
})
}
# Rodando a aplicação Shiny
shinyApp(ui = ui, server = server)
# Definindo a UI (interface do usuário)
ui <- fluidPage(
titlePanel("Exemplo de Aplicação Shiny"),
sidebarLayout(
sidebarPanel(
sliderInput("num_points", "Número de pontos:",
min = 10, max = 1000, value = 100)
),
mainPanel(
plotOutput("scatter_plot")
)
)
)
ui <- fluidPage(
titlePanel("Exemplo de Aplicação Shiny"),
sidebarLayout(
sidebarPanel(
sliderInput("num_points", "Número de pontos:",
min = 10, max = 1000, value = 100)
),
mainPanel(
plotOutput("scatter_plot")
)
)
)
# Definindo o server (servidor)
server <- function(input, output) {
# Gerando os dados aleatórios com base no número de pontos escolhido pelo usuário
data <- reactive({
num_points <- input$num_points
data <- data.frame(
x = rnorm(num_points),
y = rnorm(num_points)
)
data
})
# Gerando o gráfico de dispersão
output$scatter_plot <- renderPlot({
data <- data()
ggplot(data, aes(x = x, y = y)) +
geom_point()
})
}
# Rodando a aplicação Shiny
shinyApp(ui = ui, server = server)
setwd("G:/Meu Drive/AI_data_lab/Cursos_ml_AI/Data Science Academey/Formação cientista de dados 2.0/Projetos_gerais/Projetos_ML/8.Machine learning - Modelagem preditiva em iot")
### Parte 1 - Carregando bibliotecas
library(dplyr)
library(Hmisc)
library(ggplot2)
library(PerformanceAnalytics)
library(corrgram)
library(zoo)
library(readr)
library(caret)
library(scales)
# Base treino
data_train <- read_csv("projeto8-training.csv")
head(data_train)
# Base teste
data_test <- read_csv("projeto8-testing.csv")
head(data_test)
### Parte 3 - Ajutando base dados
data <- rbind(data_train, data_test)
# Visualizando base dados nova
head(data)
# Visualizando nomes da coluna
names(data)
## Transformação dados para data
data$date <- strptime(as.character(data$date),format="%Y-%m-%d %H:%M")
data$date <- as.POSIXct(data$date , tz="UTC")
data$day   <- as.integer(format(data$date, "%d"))
data$month <- as.factor(format(data$date, "%m"))
data$hour <- as.integer(format(data$date, "%H"))
# Transformação em dados númericas para variáveis categóricas
data$lights <- as.factor(data$lights)
# Valores ausentes
any(is.na(data))
# Dados estatisticos numéricas
describe(data)
# Análise Estatística - Correlação
data_nub <- numeric.vars <- c('Appliances','T1','RH_1','T2',
'RH_2','T3','RH_3','T4','RH_4',
'T5','RH_5','T6','RH_6','T7',
'RH_7','T8','RH_8','T9','RH_9',
'T_out','Press_mm_hg','RH_out','Windspeed',
'Visibility','Tdewpoint',
'rv1','rv2','NSM')
data_corr <- cor(data[,data_nub])
# Visualizando correlação com "Spearman"
chart.Correlation(data_corr,
method="spearman",
histogram=TRUE,
pch=16)
# Visualizando correlação com dados númericos
data_corr <- corrgram(data_corr, order=TRUE,
lower.panel = panel.shade,
upper.panel = panel.pie,
text.panel = panel.txt)
# Gráfico variavel target "Appliances"
ggplot(data, aes(x = Appliances)) +
geom_histogram(fill = "steelblue", color = "black", alpha = 0.7) +
labs(title = "Variavel target - Appliances",
x = "Categorias",
y = "Contagem")
# Visualizando o consumo de energia por dia x mes
ggplot(data)+
geom_bar(aes(x=day, y=Appliances, color = "steelblue"), stat="identity")+
scale_y_continuous(name="Consumo Energia")+
facet_wrap(~month, scale="free")+
theme_bw()
# Visualizando o consumo de energia por dia x semana e final de semana
ggplot(data)+
geom_bar(aes(x=day, y=Appliances), stat="identity", color = "steelblue")+
scale_y_continuous(name="Consumo Energia")+
facet_wrap(~WeekStatus, scale="free")+
theme_bw()
scale.features <- function(data, variables){
for (variable in variables){
data[[variable]] <- scale(data[[variable]], center=T, scale=T)
}
return(data)
}
# Variaveis para normalização dados
norml_data <- numeric.vars <- c('T1','RH_1','T2','RH_2','T3','RH_3','T4','RH_4','T5','RH_5','T6','RH_6','T7','RH_7','T8','RH_8','T9','RH_9',
'T_out','Press_mm_hg','RH_out','Windspeed','Visibility','Tdewpoint','rv1','rv2','NSM')
# Normalização dados
data <- scale.features(data, norml_data)
data
# Transformando data index
rownames(data) <- data$date
data$date <- NULL
# Transformando data index
rownames(data) <- data$date
data$date <- NULL
# Treino teste modelo
data_splits <- createDataPartition(data$Appliances,
p=0.7,
list = FALSE)
# Dados treino e teste
train <- data[data_splits,]
test <- data[-data_splits,]
# Verificando dados treino e teste
nrow(train)
nrow(test)
train <- na.omit(train)
mean_value <- mean(train$Appliances, na.rm = TRUE)
train$Appliances[is.na(train$Appliances)] <- mean_value
# Parte 7 - Modelo machine learning
# Modelo 01 - Regressão Logística Multinomial
library(nnet)
# Treine o modelo de Regressão Logística Multinomial
modelo_logistica <- multinom(Appliances ~ .,
data = train)
# Treine o modelo de Regressão Logística Multinomial
modelo_logistica <- multinom(Appliances ~ .,
data = train)
# Treine o modelo de Regressão Logística Multinomial
modelo_logistica <- multinom(Appliances ~ .,
data = train,
MaxNWts = 1000)
# Parte 7 - Modelo machine learning
# Modelo 01 - Regressão Logística Multinomial
library(nnet)
# Treine o modelo de Regressão Logística Multinomial
modelo_logistica <- multinom(Appliances ~ .,
data = train,
MaxNWts = 1000)
# Treine o modelo SVM para classificação
# Modelo 02 - SVM
modelo_svm <- svm(Appliances ~ .,
data = train)
# Treine o modelo SVM para classificação
# Modelo 02 - SVM
library(e1071)
modelo_svm <- svm(Appliances ~ .,
data = train)
modelo_svm
# Sumario do modelo
summary(modelo_svm)
# Faça previsões no conjunto de teste
previsoes_svm <- predict(modelo_svm, newdata = test)
previsoes_svm
# Avalie a precisão do modelo SVM
precisao <- mean(previsoes_svm == test$Appliances)
cat("Precisão do modelo SVM:", precisao, "\n")
## Modelo 03 - Gradient Boosting - XGBoost
library(xgboost)
# Treine o modelo Gradient Boosting usando xgboost
modelo_xgboost <- xgboost(data = as.matrix(train[, -3]),
label = train$Appliances,
nrounds = 100,
objective = "binary:logistic")
library(dplyr)
library(Hmisc)
library(ggplot2)
library(PerformanceAnalytics)
library(corrgram)
library(zoo)
library(readr)
library(caret)
library(scales)
# Base treino
data_train <- read_csv("projeto8-training.csv")
head(data_train)
View(data_train)
# Base teste
data_test <- read_csv("projeto8-testing.csv")
head(data_test)
View(data_test)
data <- rbind(data_train, data_test)
# Visualizando base dados nova
head(data)
# Visualizando nomes da coluna
names(data)
## Transformação dados para data
data$date <- strptime(as.character(data$date),format="%Y-%m-%d %H:%M")
data$date <- as.POSIXct(data$date , tz="UTC")
data$day   <- as.integer(format(data$date, "%d"))
data$month <- as.factor(format(data$date, "%m"))
data$hour <- as.integer(format(data$date, "%H"))
# Transformação em dados númericas para variáveis categóricas
data$lights <- as.factor(data$lights)
# Valores ausentes
any(is.na(data))
# Dados estatisticos numéricas
describe(data)
# Análise Estatística - Correlação
data_nub <- numeric.vars <- c('Appliances','T1','RH_1','T2',
'RH_2','T3','RH_3','T4','RH_4',
'T5','RH_5','T6','RH_6','T7',
'RH_7','T8','RH_8','T9','RH_9',
'T_out','Press_mm_hg','RH_out','Windspeed',
'Visibility','Tdewpoint',
'rv1','rv2','NSM')
data_corr <- cor(data[,data_nub])
# Visualizando correlação com "Spearman"
chart.Correlation(data_corr,
method="spearman",
histogram=TRUE,
pch=16)
# Visualizando correlação com dados númericos
data_corr <- corrgram(data_corr, order=TRUE,
lower.panel = panel.shade,
upper.panel = panel.pie,
text.panel = panel.txt)
# Gráfico variavel target "Appliances"
ggplot(data, aes(x = Appliances)) +
geom_histogram(fill = "steelblue", color = "black", alpha = 0.7) +
labs(title = "Variavel target - Appliances",
x = "Categorias",
y = "Contagem")
# Visualizando o consumo de energia por dia x mes
ggplot(data)+
geom_bar(aes(x=day, y=Appliances, color = "steelblue"), stat="identity")+
scale_y_continuous(name="Consumo Energia")+
facet_wrap(~month, scale="free")+
theme_bw()
# Visualizando o consumo de energia por dia x semana e final de semana
ggplot(data)+
geom_bar(aes(x=day, y=Appliances), stat="identity", color = "steelblue")+
scale_y_continuous(name="Consumo Energia")+
facet_wrap(~WeekStatus, scale="free")+
theme_bw()
# Normalização
scale.features <- function(data, variables){
for (variable in variables){
data[[variable]] <- scale(data[[variable]], center=T, scale=T)
}
return(data)
}
# Variaveis para normalização dados
norml_data <- numeric.vars <- c('T1','RH_1','T2','RH_2','T3','RH_3','T4','RH_4','T5','RH_5','T6','RH_6','T7','RH_7','T8','RH_8','T9','RH_9',
'T_out','Press_mm_hg','RH_out','Windspeed','Visibility','Tdewpoint','rv1','rv2','NSM')
# Normalização dados
data <- scale.features(data, norml_data)
data
# Treino teste modelo
data_splits <- createDataPartition(data$Appliances,
p=0.7,
list = FALSE)
# Treino teste modelo
data_splits <- createDataPartition(data$Appliances,
p=0.7,
list = FALSE)
# Dados treino e teste
train <- data[data_splits,]
test <- data[-data_splits,]
# Verificando dados treino e teste
nrow(train)
nrow(test)
# Treino teste modelo
data_splits <- createDataPartition(data$Appliances,
p=0.7,
list = FALSE)
# Treino teste modelo
data_splits <- createDataPartition(data$Appliances,
p=0.7,
list = FALSE)
# Dados treino e teste
train <- data[data_splits,]
test <- data[-data_splits,]
# Verificando dados treino e teste
nrow(train)
nrow(test)
# Verificando dados treino e teste
nrow(train)
nrow(test)
train <- na.omit(train)
mean_value <- mean(train$Appliances, na.rm = TRUE)
train$Appliances[is.na(train$Appliances)] <- mean_value
# Importando biblioteca
library(randomForest)
# Criando modelo Random forest
modelo_rf <- randomForest(Appliances ~ .,
data = train,
ntree = 100)
# Base treino
data_train <- read_csv("projeto8-training.csv")
