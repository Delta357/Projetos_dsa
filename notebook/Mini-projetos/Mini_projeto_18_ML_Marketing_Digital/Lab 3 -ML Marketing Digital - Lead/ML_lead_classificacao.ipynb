{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3a771d",
   "metadata": {},
   "source": [
    "# Lab 3 - Machine Learning \n",
    "\n",
    "## Marketing Digital Prevendo Número de Usuários Convertidos\n",
    "\n",
    "**Descrição projeto**\n",
    "\n",
    "Você foi contratado como Cientista de Dados por uma empresa que comercializa produtos digitais. A empresa trabalha diversas estratégias de Marketing Digital e gostaria de ter um modelo de Machine Learning capaz de prever quantos usuários serão convertidos (ou seja,quantas pessoas comprarão os produtos da empresa) após cada campanha. \n",
    "\n",
    "Conseguindo fazer a previsão, a empresa pode ter uma ideia mais clara de quanto deve investir em cada campanha e\n",
    "o retorno esperado. Isso ajudará também no planejamento da empresa para comercialização e entrega do seu produto digital, além do uso de ferramentas e mídias sociais.\n",
    "\n",
    "Dados históricos de campanhas passadas estão disponíveis e seu trabalho como Cientista de Dados é construir um modelo que, ao receber novos dados, seja capaz de prever o número de usuários convertidos em uma campanha de Marketing Digital. Além disso, o Gestor de Marketing precisa saber qual seria o aumento no número de usuários convertidos se aumentar em 1\n",
    "unidade o valor gasto em uma campanha. \n",
    "\n",
    "Entretanto, os dados têm problemas (exatamente o que você encontrará no dia a dia) e você deve detectar esses problemas, decidir a melhor estratégia para resolvê-los e então criar seu modelo. Pode ser necessário criar diferentes versões do modelo até chegar ao modelo ideal. \n",
    "\n",
    "Quando chegar à versão ideal do modelo, você deve fornecer uma interpretação completa de como o modelo gera o resultado final para que os gestores tenham mais confiança no uso do modelo.\n",
    "\n",
    "Por fim, você deve fornecer uma forma de fazer o deploy do modelo e usá-lo imediatamente com novos dados.\n",
    "\n",
    "**Obejtivos**\n",
    "\n",
    "**Problema 2 - Pergunta de Negócio do Lab 3**\n",
    "\n",
    "Um Lead será convertido? Sim ou Não? Qual a probabilidade? (Classificação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a10239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Versões das bibliotecas\n",
      "\n",
      "numpy     : 1.23.5\n",
      "seaborn   : 0.12.2\n",
      "re        : 2.2.1\n",
      "matplotlib: 3.7.2\n",
      "pandas    : 2.0.3\n",
      "watermark : 2.4.3\n",
      "\n",
      "Versão python neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotecas \n",
    "\n",
    "# Bibliotecas sistema\n",
    "import re\n",
    "import random\n",
    "import unicodedata\n",
    "import itertools\n",
    "\n",
    "# Biblioteca para manipulação de arquivos\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "# Visualização de dados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar as versões das bibliotecas\n",
    "import watermark\n",
    "\n",
    "# Versões das bibliotecas\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Versões das bibliotecas\" --iversions\n",
    "\n",
    "# Configuração para os gráficos largura e layout dos graficos\n",
    "sns.set_palette(\"Accent\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale=1.8)\n",
    "color = sns.color_palette()\n",
    "\n",
    "# Warnings retirar alertas \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Versão do python\n",
    "from platform import python_version\n",
    "print('Versão python neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4b579",
   "metadata": {},
   "source": [
    "## Base dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9d67a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Base dados\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Base dados\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os 5 primeiros dados\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ceb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os 5 últimos dados\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info dados\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo dados\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70475f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de colunas e linhas \n",
    "print(\"Números de linhas: {}\" .format(data.shape[0]))\n",
    "print(\"Números de colunas: {}\" .format(data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo valores ausentes e valores únicos\n",
    "print(\"\\nMissing values\\n\", data.isnull().sum().values.sum())\n",
    "print(\"\\nUnique values\\n\",data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc87756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando dados ausentes\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa71edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados duplicados\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3fac7",
   "metadata": {},
   "source": [
    "## Análise exploratória de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbba3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.countplot(data=data, x='converteu', hue=\"converteu\")\n",
    "\n",
    "# Adicione rótulos aos eixos e um título\n",
    "plt.xlabel('Converteu')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title(\"Distribuição da Variável 'Converteu'\")\n",
    "\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92115247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(data = data, x=\"converteu\", y=\"numero_cliques\", hue=\"converteu\")\n",
    "# Adicione rótulos aos eixos e um título\n",
    "plt.xlabel('Converteu')\n",
    "plt.ylabel('Número de Cliques')\n",
    "plt.title(\"Boxplot - Número de Cliques por Conversão'\")\n",
    "\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='faixa_etaria')\n",
    "\n",
    "# Adicione rótulos aos eixos e um título\n",
    "plt.xlabel('Faixa Etária')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title('Distribuição de Faixa Etária')\n",
    "\n",
    "# Rotacione os rótulos do eixo x para melhorar a legibilidade (opcional)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f36f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de dispersão\n",
    "plt.figure(figsize=(10, 8))  \n",
    "sns.scatterplot(data=data, x='numero_acessos', y='numero_cliques', hue=\"converteu\")\n",
    "\n",
    "# Adicione rótulos aos eixos e um título\n",
    "plt.xlabel('Número de Acessos')\n",
    "plt.ylabel('Número de Cliques')\n",
    "plt.title('Relação entre Número de Acessos e Número de Cliques')\n",
    "\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método groupby() para agrupar os dados pela coluna 'cidade' e calcule a média usando o método mean()\n",
    "dados_sumarizados = data.groupby('cidade')['numero_acessos'].mean().reset_index()\n",
    "\n",
    "# O resultado será um novo DataFrame com a média do número de acessos por cidade\n",
    "print(dados_sumarizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras\n",
    "plt.figure(figsize=(10, 8))  \n",
    "sns.barplot(x=\"cidade\", y=\"numero_acessos\", data=dados_sumarizados)\n",
    "# Adicione rótulos aos eixos e um título\n",
    "plt.xlabel('Cidade')\n",
    "plt.ylabel('Média do Número de Acessos')\n",
    "plt.title('Gráfico de Barras - Média do Número de Acessos por Cidade')\n",
    "\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53bf71",
   "metadata": {},
   "source": [
    "## Features modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88803fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divida os dados em recursos (X) e variável alvo (y)\n",
    "\n",
    "# Recursos\n",
    "x = data.drop('converteu', axis=1)  \n",
    "\n",
    "# Variável alvo\n",
    "y = data['converteu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35248d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando features (x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62527139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando features (y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a09093",
   "metadata": {},
   "source": [
    "## Pré-Processamento e Encoding de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b6060",
   "metadata": {},
   "source": [
    "Pré-processamento e codificação (encoding) de variáveis categóricas são etapas importantes na preparação de dados para modelos de machine learning. Abaixo, descreverei essas etapas e fornecerei um exemplo de como realizar essas operações usando Python e a biblioteca pandas.\n",
    "\n",
    "## Pré-Processamento de Variáveis Categóricas\n",
    "\n",
    "**Identificação de Variáveis Categóricas:** Primeiro, identifique as colunas do seu conjunto de dados que contêm variáveis categóricas. Essas são colunas que contêm informações não numéricas, como categorias, nomes, cores, etc.\n",
    "\n",
    "\n",
    "**Tratamento de Valores Ausentes:** Verifique se há valores ausentes nas variáveis categóricas e decida como tratá-los (por exemplo, preenchendo com um valor padrão ou eliminando as linhas com valores ausentes).\n",
    "\n",
    "\n",
    "**Codificação de Variáveis Categóricas:** Converta as variáveis categóricas em um formato numérico que os modelos de machine learning possam entender. Existem várias técnicas para fazer isso.\n",
    "\n",
    "\n",
    "**Codificação de Variáveis Categóricas**\n",
    "\n",
    "\n",
    "**Label Encoding:** Esta técnica é usada quando uma variável categórica tem duas categorias únicas. Por exemplo, \"sim\" e \"não\" podem ser codificadas como 1 e 0, respectivamente.\n",
    "\n",
    "\n",
    "**One-Hot Encoding:** É usada quando uma variável categórica tem mais de duas categorias únicas. Cria colunas binárias (0 ou 1) para cada categoria. O pandas possui uma função get_dummies() que facilita essa codificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aplicando label encoding à variável alvo\n",
    "\n",
    "# Importando biblioteca \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codifique as variáveis categóricas, se necessário\n",
    "le = LabelEncoder()\n",
    "X_encoded = x.apply(lambda col: le.fit_transform(col) if col.dtype == 'object' else col)\n",
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando dados\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplique o Label Encoding às variáveis categóricas\n",
    "data['cidade'] = le.fit_transform(data['cidade'])\n",
    "data['cor_da_pele'] = le.fit_transform(data['cor_da_pele'])\n",
    "data['navegador_web'] = le.fit_transform(data['navegador_web'])\n",
    "\n",
    "# Visualizando \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6a2bc",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Praticamente todos os algoritmos de Aprendizado de Máquina possuem entradas e saídas. As entradas são formadas por colunas de dados estruturados, onde cada coluna recebe o nome de feature, também conhecido como variáveis independentes ou atributos. Essas features podem ser palavras, pedaços de informação de uma imagem, etc. Os modelos de aprendizado de máquina utilizam esses recursos para classificar as informações.\n",
    "Por exemplo, sedentarismo e fator hereditário são variáveis independentes para quando se quer prever se alguém vai ter câncer ou não\n",
    "\n",
    "As saídas, por sua vez, são chamadas de variáveis dependentes ou classe, e essa é a variável que estamos tentando prever. O nosso resultado pode ser 0 e 1 correspondendo a 'Não' e 'Sim' respectivamente, que responde a uma pergunta como: \"Fulano é bom pagador?\" ou a probabilidade de alguém comprar um produto ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in data.columns:\n",
    "    if data[i].dtype==np.number:\n",
    "        continue\n",
    "    data[i]= LabelEncoder().fit_transform(data[i])\n",
    "    \n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divida os dados em recursos (X) e variável alvo (y)\n",
    "\n",
    "# Recursos\n",
    "data_train_x = data.drop('converteu', axis=1)  \n",
    "\n",
    "# Variável alvo\n",
    "data_train_y = data['converteu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando features (x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando features (y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9864ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando dataset limpo\n",
    "data.to_csv(\"datataset_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14122429",
   "metadata": {},
   "source": [
    "## Treino teste\n",
    "\n",
    "- Dividir o conjunto de dados em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando biblioteca\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train_x, \n",
    "                                                    data_train_y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando dados treino\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62598179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando dados teste\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8c323",
   "metadata": {},
   "source": [
    "## Machine learning - Modelagem Preditiva\n",
    "\n",
    "**Modelo 01 - Regressão logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando biblioteca\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Criando modelo regressão logistica\n",
    "modelo_regressao_logistica = LogisticRegression()\n",
    "\n",
    "# Treinamento modelo\n",
    "modelo_regressao_logistica_fit = modelo_regressao_logistica.fit(X_train, y_train)\n",
    "\n",
    "# Visualizando modelo\n",
    "modelo_regressao_logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d313807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score modelo\n",
    "modelo_score = modelo_regressao_logistica.score(X_train, y_train)\n",
    "print(\"Model - Regressão logistica: %.2f\" % (modelo_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bad7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão modelo\n",
    "modelo_regressao_logistica_pred = modelo_regressao_logistica.predict(X_test)\n",
    "modelo_regressao_logistica_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a29bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_regressao_logistica = accuracy_score(y_test, modelo_regressao_logistica_pred)\n",
    "print(\"Accuracy - Regressão logistica: %.2f\" % (accuracy_regressao_logistica * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix_confusion = confusion_matrix(y_test, modelo_regressao_logistica_pred)\n",
    "\n",
    "print('Confusion matrix - Regressão logistica \\n\\n', matrix_confusion)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "roc = modelo_regressao_logistica.predict_proba(X_test)[:,1]\n",
    "tfp, tvp, limite = roc_curve(y_test, roc)\n",
    "print('roc_auc', roc_auc_score(y_test, roc))\n",
    "\n",
    "plt.subplots(1, figsize=(10,8))\n",
    "plt.title('Curva ROC - Regressão logistica')\n",
    "plt.plot(tfp,tvp)\n",
    "plt.xlabel('Especifidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], ls=\"--\", c = 'red')\n",
    "plt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification = classification_report(y_test, modelo_regressao_logistica_pred)\n",
    "print(\"Modelo 01 - Regressão logistica\")\n",
    "print()\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9364076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "precision = precision_score(y_test, modelo_regressao_logistica_pred)\n",
    "Recall = recall_score(y_test, modelo_regressao_logistica_pred)\n",
    "Accuracy = accuracy_score(y_test, modelo_regressao_logistica_pred)\n",
    "F1_Score = f1_score(y_test, modelo_regressao_logistica_pred)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c98eb",
   "metadata": {},
   "source": [
    "## Modelo 02 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando biblioteca\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Criando modelo \n",
    "modelo_arvore_cla_1 = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "\n",
    "# Treinamento modelo\n",
    "modelo_arvore_cla_fit = modelo_arvore_cla_1.fit(X_train, y_train)\n",
    "\n",
    "# Visualizando modelo\n",
    "modelo_arvore_cla_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be118eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score modelo\n",
    "modelo_arvore_scor = modelo_arvore_cla_1.score(X_train, y_train)\n",
    "print(\"Modelo - Decision Tree Classifier: %.2f\" % (modelo_arvore_scor * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão do modelo\n",
    "modelo_arvore_pred = modelo_arvore_cla_1.predict(X_test)\n",
    "modelo_arvore_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25304d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acuracia_decision_tree = accuracy_score(y_test, modelo_arvore_pred)\n",
    "print(\"Acuracia - Decision Tree: %.2f\" % (acuracia_decision_tree * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be926b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = modelo_arvore_cla_1.predict_proba(X_test)[:,1]\n",
    "tfp, tvp, limite = roc_curve(y_test, roc)\n",
    "print('roc_auc', roc_auc_score(y_test, roc))\n",
    "\n",
    "plt.subplots(1, figsize=(5,5))\n",
    "plt.title('Curva ROC - Arvore')\n",
    "plt.plot(tfp,tvp)\n",
    "plt.xlabel('Especifidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], ls=\"--\", c = 'red')\n",
    "plt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0707ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "matrix_confusion2 = confusion_matrix(y_test, modelo_arvore_pred)\n",
    "\n",
    "print('Confusion matrix - Decision Tree \\n\\n', matrix_confusion2)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion2[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion2[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion2[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion2[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion2, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_test, modelo_arvore_pred)\n",
    "print(\"Modelo - Decision Tree\")\n",
    "print(\"\\n\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6865cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, modelo_arvore_pred)\n",
    "Recall = recall_score(y_test, modelo_arvore_pred)\n",
    "Accuracy = accuracy_score(y_test, modelo_arvore_pred)\n",
    "F1_Score = f1_score(y_test, modelo_arvore_pred)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6f9da",
   "metadata": {},
   "source": [
    "## Modelo 03 - Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando biblioteca\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Criando modelo\n",
    "model_naive_bayes = GaussianNB()\n",
    "\n",
    "# Treinamento modelo\n",
    "model_naive_bayes_fit = model_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Visualizando modelo\n",
    "model_naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score modelo\n",
    "model_naive_bayes_score = model_naive_bayes.score(X_train, y_train)\n",
    "print(\"Modelo - Naive Bayes: %.2f\" % (model_naive_bayes_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão do modelo - Naive bayes\n",
    "model_naive_bayes_pred_predict = model_naive_bayes.predict(X_test)\n",
    "model_naive_bayes_pred_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão com função probabiliestico do modelo - Naive bayes\n",
    "model_naive_bayes_pred = model_naive_bayes.predict_proba(X_test)\n",
    "model_naive_bayes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa13a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy model\n",
    "accuracy = accuracy_score(y_test, model_naive_bayes_pred_predict)\n",
    "print(\"Accuracy Naive bayes: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a859368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix confusion\n",
    "matrix_confusion3 = confusion_matrix(y_test, model_naive_bayes_pred_predict)\n",
    "\n",
    "print('Confusion matrix - Naive bayes \\n\\n', matrix_confusion3)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion3[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion3[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion3[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion3[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion3, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); \n",
    "ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = model_naive_bayes.predict_proba(X_test)[:,1]\n",
    "tfp, tvp, limite = roc_curve(y_test, roc)\n",
    "print('roc_auc', roc_auc_score(y_test, roc))\n",
    "\n",
    "plt.subplots(1, figsize=(5,5))\n",
    "plt.title('Curva ROC - Naive bayes')\n",
    "plt.plot(tfp,tvp)\n",
    "plt.xlabel('Especifidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], ls=\"--\", c = 'red')\n",
    "plt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report modelo\n",
    "class_report = classification_report(y_test, model_naive_bayes_pred_predict)\n",
    "print(\"Modelo 03 - Naive Bayes\")\n",
    "print(\"\\n\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b252619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas modelo\n",
    "precision = precision_score(y_test, model_naive_bayes_pred_predict)\n",
    "Recall = recall_score(y_test, model_naive_bayes_pred_predict)\n",
    "Accuracy = accuracy_score(y_test, model_naive_bayes_pred_predict)\n",
    "F1_Score = f1_score(y_test, model_naive_bayes_pred_predict)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d1d19",
   "metadata": {},
   "source": [
    "## Modelo 04 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando modelo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Treinamento modelo max_depth - determinando total de árvore, random_state 0\n",
    "model_random_forest = RandomForestClassifier(max_depth = 2, random_state = 0) \n",
    "\n",
    "# Dados de treino, teste de x, y\n",
    "model_random_forest_fit = model_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Visualizando modelo\n",
    "model_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor da Accuracy do algoritmo \n",
    "model_random_forest_score = model_random_forest.score(X_train, y_train)\n",
    "print(\"Score - Modelo random forest: %.2f\" % (model_random_forest_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e65e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão do modelo\n",
    "model_random_forest_regressor_pred = model_random_forest.predict(X_test)\n",
    "model_random_forest_regressor_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9988e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy modelo\n",
    "accuracy_random_forest = accuracy_score(y_test, model_random_forest_regressor_pred)\n",
    "print(\"Accuracy - Random forest: %.2f\" % (accuracy_random_forest * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57378d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "matrix_confusion4 = confusion_matrix(y_test, model_random_forest_regressor_pred)\n",
    "\n",
    "print('Confusion matrix - Random forest \\n\\n', matrix_confusion4)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion4[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion4[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion4[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion4[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion4, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); \n",
    "ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1146cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "roc = model_random_forest.predict_proba(X_test)[:,1]\n",
    "tfp, tvp, limite = roc_curve(y_test, roc)\n",
    "print('roc_auc', roc_auc_score(y_test, roc))\n",
    "\n",
    "plt.subplots(1, figsize=(5,5))\n",
    "plt.title('Curva ROC')\n",
    "plt.plot(tfp,tvp)\n",
    "plt.xlabel('Especifidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], ls=\"--\", c = 'red')\n",
    "plt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "classification = classification_report(y_test, model_random_forest_regressor_pred)\n",
    "print(\"Modelo 04 - Random forest\")\n",
    "print()\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas modelo modelo Random forest\n",
    "precision = precision_score(y_test, model_random_forest_regressor_pred)\n",
    "Recall = recall_score(y_test, model_random_forest_regressor_pred)\n",
    "Accuracy = accuracy_score(y_test, model_random_forest_regressor_pred)\n",
    "F1_Score = f1_score(y_test, model_random_forest_regressor_pred)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b07d4",
   "metadata": {},
   "source": [
    "## Modelo 05 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando modelo\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Criando modelo\n",
    "model_xgb = XGBClassifier()\n",
    "\n",
    "# Treinamento modelo\n",
    "model_xgb_fit = model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Visualizando modelo\n",
    "model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score modelo\n",
    "model_xgb_score = model_xgb.score(X_train, y_train)\n",
    "print(\"Modelo - XGBoost: %.2f\" % (model_xgb_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507609fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão do modelo - XGBoost\n",
    "\n",
    "xgb_pred = model_xgb.predict(X_test)\n",
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy modelo\n",
    "accuracy_XGBoost = accuracy_score(y_test, xgb_pred)\n",
    "print(\"Accuracy - XGBoost: %.2f\" % (accuracy_XGBoost * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d01d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix modelo\n",
    "matrix_confusion5 = confusion_matrix(y_test, xgb_pred)\n",
    "\n",
    "print('Confusion matrix - XGBoost \\n\\n', matrix_confusion5)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion5[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion5[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion5[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion5[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion5, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); \n",
    "ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70089664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "roc = model_xgb.predict_proba(X_test)[:,1]\n",
    "tfp, tvp, limite = roc_curve(y_test, roc)\n",
    "print('roc_auc', roc_auc_score(y_test, roc))\n",
    "\n",
    "plt.subplots(1, figsize=(5,5))\n",
    "plt.title('Curva ROC')\n",
    "plt.plot(tfp,tvp)\n",
    "plt.xlabel('Especifidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], ls=\"--\", c = 'red')\n",
    "plt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "classification = classification_report(y_test, xgb_pred)\n",
    "print(\"Modelo 05 - XGBoost\")\n",
    "print()\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas modelo\n",
    "precision = precision_score(y_test, xgb_pred)\n",
    "Recall = recall_score(y_test, xgb_pred)\n",
    "Accuracy = accuracy_score(y_test, xgb_pred)\n",
    "F1_Score = f1_score(y_test, xgb_pred)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d956741",
   "metadata": {},
   "source": [
    "## Modelo 06 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando biblioteca\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Criando modelo\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "\n",
    "# Treinamento modelo\n",
    "model_gradient_boosting_fit = model_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Visualizando modelo\n",
    "model_gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score modelo\n",
    "model_gradient_boosting_score = model_gradient_boosting.score(X_train, y_train)\n",
    "print(\"Modelo Score do Gradient Boosting: %.2f\" % (model_gradient_boosting_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão do modelo - Gradient Boosting\n",
    "\n",
    "model_gradient_boosting_pred = model_gradient_boosting.predict(X_test)\n",
    "model_gradient_boosting_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f260160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score modelo\n",
    "accuracy_model_gradient_boosting = accuracy_score(y_test, model_gradient_boosting_pred)\n",
    "print(\"Acurácia - Gradient boosting: %.2f\" % (accuracy_model_gradient_boosting * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "matrix_confusion6 = confusion_matrix(y_test, model_gradient_boosting_pred)\n",
    "\n",
    "print('Confusion matrix - Gradient Boosting \\n\\n', matrix_confusion6)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion6[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion6[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion6[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion6[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion6, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); \n",
    "ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "roc = model_gradient_boosting.predict_proba(X_test)[:,1]\n",
    "tfp, tvp, limite = roc_curve(y_test, roc)\n",
    "print('roc_auc', roc_auc_score(y_test, roc))\n",
    "\n",
    "plt.subplots(1, figsize=(10,5))\n",
    "plt.title('Curva ROC - Gradient boosting')\n",
    "plt.plot(tfp,tvp)\n",
    "plt.xlabel('Especifidade')\n",
    "plt.ylabel('Sensibilidade')\n",
    "plt.plot([0, 1], ls=\"--\", c = 'red')\n",
    "plt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f693ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "classification = classification_report(y_test, xgb_pred)\n",
    "print(\"Modelo 06 - Gradient boosting\")\n",
    "print()\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d535b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas modelo\n",
    "precision = precision_score(y_test, model_gradient_boosting_pred)\n",
    "Recall = recall_score(y_test, model_gradient_boosting_pred)\n",
    "Accuracy = accuracy_score(y_test, model_gradient_boosting_pred)\n",
    "F1_Score = f1_score(y_test, model_gradient_boosting_pred)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428b903",
   "metadata": {},
   "source": [
    "## Modelo 07 - Light Gradient Boosting Machine (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8104f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Importando biblioteca\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Defina os hiperparâmetros do modelo\n",
    "parametros = {\n",
    "    'objective': 'binary',  # Para problemas de classificação binária\n",
    "    'metric': 'binary_logloss',  # Métrica de avaliação\n",
    "    'boosting_type': 'gbdt',  # Tipo de boosting\n",
    "    'num_leaves': 31,  # Número máximo de folhas em cada árvore\n",
    "    'learning_rate': 0.05,  # Taxa de aprendizado\n",
    "}\n",
    "\n",
    "# Crie um dataset LightGBM a partir dos dados\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Treine o modelo\n",
    "num_round = 250  # Número de iterações\n",
    "modelo_LightGBM = lgb.train(parametros, train_data, num_round)\n",
    "modelo_LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9386f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo em um arquivo\n",
    "modelo_LightGBM.save_model('modelo_lightgbm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c64b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça previsões no conjunto de teste\n",
    "modelo_pred = modelo_LightGBM.predict(X_test, num_iteration=modelo_LightGBM.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta as previsões em classes (0 ou 1)\n",
    "y_pred_binario = [1 if pred > 0.5 else 0 for pred in modelo_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b20956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score modelo\n",
    "accuracy_LightGBM_boosting = accuracy_score(y_test, y_pred_binario)\n",
    "print(\"Acurácia - LightGBM: %.2f\" % (accuracy_LightGBM_boosting * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "matrix_confusion7 = confusion_matrix(y_test, y_pred_binario)\n",
    "\n",
    "print('Confusion matrix - LightGBM \\n\\n', matrix_confusion7)\n",
    "print('\\nTrue Positives(TP) = ', matrix_confusion7[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', matrix_confusion7[1,1])\n",
    "print('\\nFalse Positives(FP) = ', matrix_confusion7[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', matrix_confusion7[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02015f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(matrix_confusion7, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
    "ax.set_title('Confusion Matrix - LightGBM'); \n",
    "ax.xaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]); \n",
    "ax.yaxis.set_ticklabels([\"Acesso\", \"Não acesso\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule a Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_binario)\n",
    "\n",
    "# Calcule a AUC (Área sob a Curva ROC)\n",
    "auc = roc_auc_score(y_test, y_pred_binario)\n",
    "\n",
    "# Plote a Curva ROC\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(fpr, tpr, label=f'Curva ROC LightGBM (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC LightGBM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f30d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "classification = classification_report(y_test, y_pred_binario)\n",
    "print(\"Modelo - 07 - LightGBM\")\n",
    "print(\"\\n\")\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "precision = precision_score(y_test, y_pred_binario)\n",
    "Recall = recall_score(y_test, y_pred_binario)\n",
    "Accuracy = accuracy_score(y_test, y_pred_binario)\n",
    "F1_Score = f1_score(y_test, y_pred_binario)\n",
    "\n",
    "precisao = pd.DataFrame({\n",
    "    \n",
    "    \"Metricas\" : [\"precision\",\n",
    "                 \"Recall\", \n",
    "                  \"Accuracy\", \n",
    "                  \"F1_Score\"],\n",
    "    \n",
    "    \"Resultado\": [precision,\n",
    "                Recall, \n",
    "                Accuracy, \n",
    "                F1_Score]})\n",
    "\n",
    "precisao.sort_values(by = \"Resultado\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b03d9d",
   "metadata": {},
   "source": [
    "## Resultados - Modelos machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados modelo\n",
    "\n",
    "modelos = pd.DataFrame({\n",
    "    \n",
    "    \"Models\" :[\"Regressão logistica\",\n",
    "               \"Random Forest\", \n",
    "               \"Decision Tree\",\n",
    "               \"Naive Bayes\",\n",
    "               \"XGBoost\",\n",
    "               \"Gradient boosting\",\n",
    "               \"LightGBM\"],\n",
    "\n",
    "    \"Acurácia\" :[accuracy_regressao_logistica,\n",
    "                 accuracy_random_forest, \n",
    "                 acuracia_decision_tree,\n",
    "                 accuracy,\n",
    "                 accuracy_XGBoost,\n",
    "                 accuracy_model_gradient_boosting,\n",
    "                 accuracy_LightGBM_boosting]})\n",
    "\n",
    "modelos.sort_values(by = \"Acurácia\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a0061",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f628db",
   "metadata": {},
   "source": [
    "Este projeto de machine learning teve como foco a classificação de diferentes modelos, incluindo XGBoost, Gradient Boosting e Decision Tree. A principal pergunta abordada foi: \"Um Lead será convertido? Sim ou Não? Qual a probabilidade?\". Durante a análise, foram exploradas várias técnicas de modelagem preditiva para responder a essa questão.\n",
    "\n",
    "Na primeira parte do projeto, exploramos a aplicação de diferentes algoritmos de classificação, como XGBoost, Gradient Boosting e Decision Tree, para determinar a probabilidade de conversão de leads. Esses modelos foram treinados e avaliados para identificar a abordagem mais eficaz na previsão de conversões. \n",
    "\n",
    "Na terceira parte do projeto, foi a fase de previsão, na qual nosso objetivo era responder à pergunta-chave: \"O lead será convertido?\". O resultado obtido indicou que a resposta do modelo \"sim\", com uma probabilidade de compra de 65%. \n",
    "\n",
    "Esse resultado é altamente relevante para estratégias de marketing digital, pois fornece informações valiosas para direcionar recursos e esforços de marketing de forma mais eficiente.\n",
    "\n",
    "Este projeto destaca a importância da aplicação de machine learning em marketing digital. Ele demonstra como modelos de classificação podem ser aproveitados para prever a probabilidade de conversão de leads, fornecendo insights cruciais para otimizar campanhas e maximizar o retorno sobre o investimento. \n",
    "\n",
    "Em resumo, trata-se de um projeto fascinante que ilustra a relevância e o potencial da inteligência artificial no contexto do marketing digital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89705d",
   "metadata": {},
   "source": [
    "# Referência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2bea9",
   "metadata": {},
   "source": [
    "Link 1 - https://www.datageeks.com.br/xgboost/\n",
    "    \n",
    "Link 2 - https://lamfo.unb.br/wp-content/uploads/2020/08/Oficina-Random-Forest-e-LGMB.pdf\n",
    "    \n",
    "Link 3 - https://acervolima.com/lightgbm-vs-xgboost-qual-algoritmo-e-melhor/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a8ed4",
   "metadata": {},
   "source": [
    "# Citação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff78dd1",
   "metadata": {},
   "source": [
    "**Esse projeto da formação cientista de dados da @Data Science Academy**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
